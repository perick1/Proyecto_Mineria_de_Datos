{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_one_hot = df_sub_one_hot.query(\"cat_periodo==2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data oversampled on class 'True'\n",
      "True     138643\n",
      "False    138643\n",
      "Name: Class, dtype: int64\n",
      "Data subsampled on class 'False'\n",
      "True     16488\n",
      "False    16488\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data_train, data_test, ytrain, ytest = train_test_split(df_sub_one_hot, df_sub_one_hot['Class'], test_size=0.3, stratify=df_sub_one_hot['Class'])\n",
    "diferencia = ytrain.value_counts()[False]-ytrain.value_counts()[True]\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "\n",
    "# oversampling sobre la clase True\n",
    "idx = np.random.choice(data_train[data_train['Class'] == True].index, size=diferencia)\n",
    "data_oversampled = pd.concat([data_train, data_train.iloc[idx]])\n",
    "print(\"Data oversampled on class 'True'\")\n",
    "print(data_oversampled['Class'].value_counts())\n",
    "\n",
    "# subsampling sobre la clase False\n",
    "idx = np.random.choice(data_train.loc[data_train.Class == False].index, size=diferencia, replace=False)\n",
    "data_subsampled = data_train.drop(data_train.iloc[idx].index)\n",
    "print(\"Data subsampled on class 'False'\")\n",
    "print(data_subsampled['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# datos test (mismo para todos los conjuntos de entrenamiento)\n",
    "X_test = data_test[data_train.columns[:-1]]\n",
    "y_test = data_test[data_train.columns[-1]]\n",
    "\n",
    "# datos entrenamiento \"originales\"\n",
    "X_orig = data_train[data_train.columns[:-1]] \n",
    "y_orig = data_train[data_train.columns[-1]] \n",
    "\n",
    "# datos entrenamiento \"oversampleados\" \n",
    "X_over = data_oversampled[data_train.columns[:-1]]\n",
    "y_over = data_oversampled[data_train.columns[-1]]\n",
    "\n",
    "# datos entrenamiento \"subsampleados\"\n",
    "X_subs = data_subsampled[data_train.columns[:-1]]\n",
    "y_subs = data_subsampled[data_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99     59419\n",
      "        True       0.95      0.86      0.91      7067\n",
      "\n",
      "    accuracy                           0.98     66486\n",
      "   macro avg       0.97      0.93      0.95     66486\n",
      "weighted avg       0.98      0.98      0.98     66486\n",
      "\n",
      "OVERSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98     59419\n",
      "        True       0.73      0.96      0.83      7067\n",
      "\n",
      "    accuracy                           0.96     66486\n",
      "   macro avg       0.86      0.96      0.90     66486\n",
      "weighted avg       0.97      0.96      0.96     66486\n",
      "\n",
      "SUBSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.98     59419\n",
      "        True       0.73      0.96      0.83      7067\n",
      "\n",
      "    accuracy                           0.96     66486\n",
      "   macro avg       0.86      0.96      0.90     66486\n",
      "weighted avg       0.97      0.96      0.96     66486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"ORIGINAL::::::::::\")\n",
    "clf_orig = DecisionTreeClassifier()\n",
    "clf_orig.fit(X_orig, y_orig)\n",
    "pred_orig = clf_orig.predict(X_test)\n",
    "print(classification_report(y_test, pred_orig))\n",
    "\n",
    "print(\"OVERSAMPLING::::::::::\")\n",
    "clf_over = DecisionTreeClassifier()\n",
    "clf_over.fit(X_over, y_over)\n",
    "pred_over = clf_over.predict(X_test)\n",
    "print(classification_report(y_test, pred_over))\n",
    "\n",
    "print(\"SUBSAMPLING::::::::::\")\n",
    "clf_subs = DecisionTreeClassifier()\n",
    "clf_subs.fit(X_subs, y_subs)\n",
    "pred_subs = clf_subs.predict(X_test)\n",
    "print(classification_report(y_test, pred_subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.81      0.89     59419\n",
      "        True       0.38      0.97      0.55      7067\n",
      "\n",
      "    accuracy                           0.83     66486\n",
      "   macro avg       0.69      0.89      0.72     66486\n",
      "weighted avg       0.93      0.83      0.86     66486\n",
      "\n",
      "OVERSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.80      0.89     59419\n",
      "        True       0.37      0.98      0.54      7067\n",
      "\n",
      "    accuracy                           0.82     66486\n",
      "   macro avg       0.69      0.89      0.72     66486\n",
      "weighted avg       0.93      0.82      0.85     66486\n",
      "\n",
      "SUBSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.80      0.89     59419\n",
      "        True       0.37      0.98      0.54      7067\n",
      "\n",
      "    accuracy                           0.82     66486\n",
      "   macro avg       0.69      0.89      0.72     66486\n",
      "weighted avg       0.93      0.82      0.85     66486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  # Naive bayes\n",
    "\n",
    "print(\"ORIGINAL::::::::::\")\n",
    "clf_orig = GaussianNB()\n",
    "clf_orig.fit(X_orig, y_orig)\n",
    "pred_orig = clf_orig.predict(X_test)\n",
    "print(classification_report(y_test, pred_orig))\n",
    "\n",
    "print(\"OVERSAMPLING::::::::::\")\n",
    "clf_over = GaussianNB()\n",
    "clf_over.fit(X_over, y_over)\n",
    "pred_over = clf_over.predict(X_test)\n",
    "print(classification_report(y_test, pred_over))\n",
    "\n",
    "print(\"SUBSAMPLING::::::::::\")\n",
    "clf_subs = GaussianNB()\n",
    "clf_subs.fit(X_subs, y_subs)\n",
    "pred_subs = clf_subs.predict(X_test)\n",
    "print(classification_report(y_test, pred_subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99     59419\n",
      "        True       0.93      0.84      0.88      7067\n",
      "\n",
      "    accuracy                           0.98     66486\n",
      "   macro avg       0.95      0.92      0.93     66486\n",
      "weighted avg       0.98      0.98      0.98     66486\n",
      "\n",
      "OVERSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.95      0.97     59419\n",
      "        True       0.69      0.95      0.80      7067\n",
      "\n",
      "    accuracy                           0.95     66486\n",
      "   macro avg       0.84      0.95      0.89     66486\n",
      "weighted avg       0.96      0.95      0.95     66486\n",
      "\n",
      "SUBSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.92      0.96     59419\n",
      "        True       0.59      0.95      0.73      7067\n",
      "\n",
      "    accuracy                           0.93     66486\n",
      "   macro avg       0.79      0.94      0.84     66486\n",
      "weighted avg       0.95      0.93      0.93     66486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"ORIGINAL::::::::::\")\n",
    "clf_orig = KNeighborsClassifier()\n",
    "clf_orig.fit(X_orig, y_orig)\n",
    "pred_orig = clf_orig.predict(X_test)\n",
    "print(classification_report(y_test, pred_orig))\n",
    "\n",
    "print(\"OVERSAMPLING::::::::::\")\n",
    "clf_over = KNeighborsClassifier()\n",
    "clf_over.fit(X_over, y_over)\n",
    "pred_over = clf_over.predict(X_test)\n",
    "print(classification_report(y_test, pred_over))\n",
    "\n",
    "print(\"SUBSAMPLING::::::::::\")\n",
    "clf_subs = KNeighborsClassifier()\n",
    "clf_subs.fit(X_subs, y_subs)\n",
    "pred_subs = clf_subs.predict(X_test)\n",
    "print(classification_report(y_test, pred_subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL::::::::::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Javi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Javi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Javi\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      1.00      0.94     59419\n",
      "        True       0.00      0.00      0.00      7067\n",
      "\n",
      "    accuracy                           0.89     66486\n",
      "   macro avg       0.45      0.50      0.47     66486\n",
      "weighted avg       0.80      0.89      0.84     66486\n",
      "\n",
      "OVERSAMPLING::::::::::\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-77b924166d4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OVERSAMPLING::::::::::\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mclf_over\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_over\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mpred_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_over\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_over\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[0;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC  # Support Vector Machine classifier\n",
    "\n",
    "print(\"ORIGINAL::::::::::\")\n",
    "clf_orig = SVC()\n",
    "clf_orig.fit(X_orig, y_orig)\n",
    "pred_orig = clf_orig.predict(X_test)\n",
    "print(classification_report(y_test, pred_orig))\n",
    "\n",
    "print(\"OVERSAMPLING::::::::::\")\n",
    "clf_over = SVC()\n",
    "clf_over.fit(X_over, y_over)\n",
    "pred_over = clf_over.predict(X_test)\n",
    "print(classification_report(y_test, pred_over))\n",
    "\n",
    "print(\"SUBSAMPLING::::::::::\")\n",
    "clf_subs = SVC()\n",
    "clf_subs.fit(X_subs, y_subs)\n",
    "pred_subs = clf_subs.predict(X_test)\n",
    "print(classification_report(y_test, pred_subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
