{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas\n",
    "1. ¿Se puede predecir las características de las matrículas para años futuros considerando los datos actuales? \n",
    "2. ¿Cuáles son las características y tendencias de las personas que se cambian de carrera? \n",
    "3. ¿Cuánto valor le agrega la acreditación a una carrera?\n",
    "4. ¿Existe una relación entre costo de carrera y otras variables?\n",
    " \n",
    "Siendo conscientes de que estamos trabajando mayoritariamente con variables categóricas, puede ser posible encontrar relaciones no lineales entre los atributos al vectorizarlos de manera más compleja que la entregada por *one hot encoding*, tal vez mediante vectores que comprendan cierta relación entre los valores del atributo, que posean cierta métrica (*word2vec* por ejemplo). De esta forma podemos permitirnos generar regresiones, predicciones o clustering más ricos en información relevante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodología \n",
    "\n",
    "Se describe a continuación, de manera detallada, la metodología para responder cada una de las 4 preguntas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1: ¿Se puede predecir las características de las matrículas para años futuros considerando los datos actuales? \n",
    "\n",
    "Antes de esto hay que replantearse la pregunta, y para esto se debe definir concretamente cuáles son las características de las matrículas. En el caso de que fueran instancias, es decir, cada matrícula ingresada, entonces esta pregunta sería equivalente a la pregunta dos: debemos predecir características en personas, aunque en este caso no nos estaríamos centrando en personas que se cambian de carrera. \n",
    "En el caso de que fueran características macroscópicas, se deben evitar preguntas triviales, que involucren directamente indicadores como promedios, varianzas, número de sucesos, etc., que debieron ser estudiadas en el hito anterior. Una alternativa interesante podría ser generar clusters con los vectores totales (luego aplicar one hot) de cada instancia. y ver su evolución temporal: ¿dónde está el centro de cada uno, por año?, ¿cómo van cambiando ciertos indicadores de validación: Inercia, Separación, Cohesión,?, ¿cómo va cambiando la densidad de clusters?. Junto a esto podemos ir comparando con valores más tangibles como promedios, varianzas, etc. (ej: varianza regional del valor de arancel).\n",
    "\n",
    "Para responder esta pregunta, se deben completar tres pasos previos:\n",
    "- Utilizar nuevamente como vectorización preliminar one hot encoding para ingresar las instancias como vectores de dimensión igual al número de columnas. Habrá que tener cuidado interpretando los clusters y el espacio vectorial en el que residen. En este vector, por ejemplo, la columna de rango de edad (ej: 18 y 20 años) tendría igual peso que la del tipo de estudio superior (ej: Doctorado); los dos marcarían un 1 en su dimensión correspondiente, y en las demás, de su misma naturaleza, un 0.\n",
    "\n",
    "- Generar Clustering con ciertos atributos seleccionados gracias a la exploración realizada en el hito 1. Con esto, y la correspondiente validación del clustering, podremos cuantificar potenciales patrones de agrupación.\n",
    "    - Primeramente se utilizará el coeficiente de Silhouette para verificar la viabilidad del cluster, si fuese negativo, se trataría de generar un vector (por instancia) preliminar compuesto de otra manera, o también podría ser interesante crear para cada columna un vector y comprobar si podemos, mediante algún tipo de operación, unificarlos todos, de forma que el clustering de cuenta de estructuras particulares.\n",
    "    - Se hará uso de la métrica Cohesión, Separación e Inercia, junto a la visualización de su matriz de proximidad, una vez encontrado un coeficiente de Silhouette positivo, con el propósito de seguir evaluando las estructuras subyacentes en los datos. \n",
    "    - Podemos tomar este proceso como una forma sistemática de vectorizar instancias, de modo que luego quedar satisfechos (o de plano probar con varias) con un encoding podremos proseguir al paso 3.\n",
    "\n",
    "- Luego de tener un vector para cada instancia, podemos reducir su dimensionalidad y  visualizar los clusters, como primera opción mediante PCA, pero existen varias por explorar. Luego de esto tendremos instancias medianamente interpretables, y que facilitarán su manejo en algoritmos de Regresión. Como ya se dijo en un inicio, otro posible estudio es el de la dinámica de los cluster, sus propiedades (ej: su densidad), y la correlación que estas variables guardan con indicadores macroscópicos en las matrículas(ej: valor arancel medio, arancel medio por región, etc.).\n",
    "\n",
    "**Nota: Esta pregunta está mayormente respondida y diseñada por Alonso Uribe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2: ¿Cuáles son las características y tendencias de las personas que se cambian de carrera? \n",
    " \n",
    "Para responder la pregunta 2 primero es importante notar que es posible determinar quienes se han cambiado de carrera con los datos actuales, por lo tanto, se utilizará clasificación para buscar perfiles de personas que podrían cambiarse de carrera en el futuro. Así, las clases posibles son “se cambió de carrera” y “no se cambió de carrera”, y nuestra clase positiva corresponde a quienes sí se han cambiado de carrera, pues es lo que queremos evitar.\n",
    "\n",
    "Entonces lo primero es disminuir la dimensionalidad de los datos, para esto se agregará una nueva columna que describe el tiempo que lleva la persona cursando su carrera actual, así esta resume la información de las columnas ``cat_periodo`` y ``ANIO_ING_CARR_ACT``, su creación sería a través de la resta de los años de ``ANIO_ING_CARR_ACT`` y ``cat_periodo``. Por otro lado, se requiere una columna que indique la clase de la fila, la que resumiría la información de las columnas ``ANIO_ING_CARR_ORI`` y ``ANIO_ING_CARR_ACT``; para obtenerla haremos una restricción con la siguiente query: ``row.cat_periodo != row.anio_ing_carr_ori and row.cat_periodo == row.anio_ing_carr_act``. De igual manera, se utiliza la información de ``NIVEL_GLOBAL`` para limitar los datos a las matriculas de pregrado, pues solo aquí tiene sentido el análisis.\n",
    "\n",
    "Adicionalmente se mantendremos las siguientes columnas;\n",
    "- `GEN_ALU`\n",
    "- `RANGO_EDAD`\n",
    "- `TIPO_INST_3`\n",
    "- `JORNADA`\n",
    "- `TIPO_PLAN_CARR`\n",
    "- `DUR_ESTUDIO_CARR`\n",
    "- `NIVEL_CARRERA_1`\n",
    "- `VALOR_MATRICULA`\n",
    "- `VALOR_ARANCEL`\n",
    "- `OECD_AREA`\n",
    "- `ACREDITADA_CARR`\n",
    "- `ACREDITADA_INST`\n",
    "\n",
    "Donde se incluye una sola columna relacionada a la duración de la carrera pues se observa una estrecha relación entre DUR_ESTUDIO_CARR y DUR_TOTAL_CARR; una correlación de 0.99. A pesar de esto siguen siendo demasiadas columnas, por lo que aplicaremos la transformación One Hot sobre los datos restringidos y eliminaremos las columnas que tengan correlación cercana a 1 o a -1. \n",
    "\n",
    "Una vez determinadas las columnas a utilizar se busca encontrar el mejor algoritmo de clasificación, para lo cual se evaluarán las métricas de los algoritmos **KNN**, **Naive Bayes**, **Support Vector Machine** y **Árbol de Decisión**. Estas métricas serán evaluadas con la técnica **holdout**, dejando $1/3$ de los datos para entrenar y aplicando estratificación sobre las particiones, pero, además, se observará el desempeño aplicando **subsampling** sobre la clase negativa, **oversampling** sobre la clase positiva y el caso en que no se aplica ninguno, esto al considerar que son pocos los alumnos que se cambian de carrera anualmente. \n",
    "\n",
    "Luego, usaremos matriz de confusión para observar el desempeño, poniendo especial atención en la métrica **recall**, dado que no es un gran problema tener falsos positivos, pues lo que se busca es mejorar la información entregada a estudiantes previo a su primera matrícula, considerando quienes tienen un perfil con mayor probabilidad de deserción de su primera carrera.\n",
    "\n",
    "Por último, observamos que tal se comporta el clasificador con datos nuevos al entrenarlo con los datos desde el año 2010 hasta el 2017 y utilizarlo sobre los datos de entre el 2018 y 2019. No se utilizarán los años del 2020 pues probablemente tienen sesgo debido a la pandemia.\n",
    "\n",
    "**Nota: Esta pregunta está mayormente respondida y diseñada por Javiera Alegria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3: ¿Cuánto valor le agrega la acreditación a una carrera?\n",
    "\n",
    "La dificultad de esta pregunta radica en definir el concepto de **valor** y preprocesar los datos de manera favorable, que faciliten el análisis con esto en mente se presenta la siguiente metodología por pasos.\n",
    "\n",
    "- Definir columnas numéricas a utilizar: Se eligen ``VALOR_ARANCEL``, ``GEN_ALU``,``FEC_NAC_ALU``, ``ANIO_ING_CARR_ORI``, ``CAT_PERIODO``, ``DUR_TOTAL_CARR``, ``ACRE_INS_ANIO``, ``ACRE_INS_DESDE_HASTA``. Estas columnas describen de buena forma las carreras, sus periodos de acreditación y precios, caracterizando también a sus alumnos. Los datos se manejan en forma de DataFrames de pandas, y realizando un subset de las columnas de interés.\n",
    "\n",
    "\n",
    "- Definir columnas categóricas a utilizar: Se eligen ``TIPO_INS_2``, ``NOMB_INST``,``CINE_F_13_AREA``, ``ACREDITADA_CARR``, ``NIVEL_CARR_2``, ``REGION_INST``. De la misma forma que el punto anterior, se agregan estas columnas al filtrado quedando un total de 14 columnas, achicando así la cantidad de datos a procesar, recordando que el dataset original contiene 49 columnas.\n",
    "\n",
    "- Preprocesado: Creación de nuevas columnas para obtener información util.\n",
    "\n",
    "    - ``EDAD_ALU``: Edad del estudiante al cual corresponde la matrícula, hace más directo el análisis de datos, variable numérica.\n",
    "    \n",
    "    - ``ANIOS_U``: Años que el estudiante lleva en la universidad, hace más directo el filtrado de datos, variable numérica.\n",
    "    \n",
    "    - ``ANIOS_RESTANTES ACRE``: Años que restan para que acabe la acreditación de la carrera, variable numérica.\n",
    "\n",
    "- Preprocesado: Modificación de variables.\n",
    "\n",
    "    - ``GEN_ALU``: Se cambia la variable de numérica a categórica.\n",
    "    \n",
    "    - ``ACRE_INST_ANIO``: Se modifican los valores nan por 0.\n",
    "    \n",
    "    - Se dejan fuera del análisis las matrículas con valores nan, o irregulares, en alguna columna, que representan menos del 1%.\n",
    "\n",
    "- Se obtienen histogramas de cada una de las variables (o columnas), diferenciando entre cuenta de acreditados y no acreditados, con el fin de analizar singularidades.\n",
    " \n",
    "- Se obtienen métricas estadísticas de los histogramas como media, mediana y desviación estandard.\n",
    "\n",
    "- Se analiza mediante gráficos (matplotlib) la evolución de los estadisticos durante los años desde 2011 al 2018. Adicionalmente se analiza la incorporación de alumnos nuevos a carreras específicas que durante esste tiempo pierdan su acreditación.  Lo mismo anterior anallizando el valor de matrícula de estas carreras.\n",
    "\n",
    "- Se realiza clustering (kmeans y herárquico), sumado a metodos de reducción de dimencionalidad (PCA , t-sne y UMAP), para caracterizar y visualizar las particularidades de la acreditación y como se agrupan distintas instituciones y carreras.\n",
    "\n",
    "**Nota: Esta pregunta está mayormente respondida y diseñada por Erick Perez**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 4: ¿Existe una relación entre costo de carrera y otras variables?\n",
    " \n",
    "Propuesta experimental:\n",
    "- Dado que esta pregunta es de carácter descriptivo, se propone utilizar técnicas de clustering para encontrar automáticamente  si hay relaciones de forma natural entre la variable valor del arancel  y otras variables numéricas, como la duración de la carrera y los años de acreditación. \n",
    "- También se propone buscar relaciones del valor del arancel con variables categóricas como la modalidad (presencial, semi-presencial o no presencial) y el tipo de jornada (diurno, vespertino), realizando codificaciones numéricas a estas categorías para poder aplicar clustering.\n",
    "- Se probarán técnicas de clustering particionales (K-Means) y jerárquicos.\n",
    "- Se estimará el k en K-Means utilizando la métrica SSE.\n",
    "- Se validará la calidad de los clustering usando la medida SSE, Matriz de similitud y el coeficiente de Silhouette. Se seleccionarán aquellos clustering que entreguen resultados más significativos.\n",
    "- A partir de los resultados obtenidos, se generarán visualizaciones del clustering y dendrogramas para identificar posibles outliers y realizar un post- procesamiento de los datos en caso de ser necesario, con el objetivo de reducir el SSE.\n",
    "\n",
    "**Nota: Esta pregunta está mayormente respondida y diseñada por Adriana Concha**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación\n",
    "\n",
    "En este hito se implementó la pregunta 2, el código se muestra a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexos\n",
    "Descripción del dataset dado por el Mineduc [aquí](http://datos.mineduc.cl/datasets/178941-er-base-de-datos-matricula-en-educacion-superior.download/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
